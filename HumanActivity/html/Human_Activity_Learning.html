
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Human Activity Learning Using Mobile Phone Data</title><meta name="generator" content="MATLAB 8.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2015-03-27"><meta name="DC.source" content="Human_Activity_Learning.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Human Activity Learning Using Mobile Phone Data</h1><!--introduction--><p>Human activity sensor data contains observations derived from sensor measurements taken from smartphones worn by people while doing different activities (walking, lying, sitting etc). The goal of this example is to provide a strategy to build a classifier that can automatically identify the activity type given the sensor measurements.</p><p>Copyright (c) 2015, MathWorks, Inc.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Description of the Data</a></li><li><a href="#5">Download data from source</a></li><li><a href="#7">Load data frome individual files and save as MAT file for reuse</a></li><li><a href="#9">Load Training Data</a></li><li><a href="#10">Display data summary</a></li><li><a href="#11">Create Table variable</a></li><li><a href="#12">Pre-process Training Data: <b>Feature Extraction</b></a></li><li><a href="#13">Train a model and assess its performance using Classification Learner</a></li><li><a href="#14">Additional Feature Extraction</a></li><li><a href="#15">Use the new features to train a model and assess its performance</a></li><li><a href="#17">Load Test Data</a></li><li><a href="#18">Visualize classifier performance on test data</a></li></ul></div><h2>Description of the Data<a name="1"></a></h2><pre>The dataset consists of accelerometer and gyroscope data captured at
50Hz. The raw sensor data contain fixed-width sliding windows of 2.56 sec
(128 readings/window). The activities performed by the subject include:
'Walking', 'ClimbingStairs', 'Sitting', 'Standing',and 'Laying'</pre><p><b>How to get the data:</b> Execute <tt>downloadSensorData</tt> and follow the instructions to download the and extract the data from the source webpage. After the files have been extracted run <tt>saveSensorDataAsMATFiles</tt>. This will create two MAT files: <tt>rawSensorData_train</tt>  and <tt>rawSensorData_test</tt> with the raw sensor data</p><div><ol><li><b>total_acc_(x/y/z)_train :</b>  Raw accelerometer sensor data</li><li><b>body_gyro_(x/y/z)_train :</b>  Raw gyroscope sensor data</li><li><b>trainActivity :</b>  Training data labels</li><li><b>testActivity  :</b>  Test data labels</li></ol></div><p>Reference:</p><p><tt>Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L.  Reyes-Ortiz. Human Activity Recognition on Smartphones using a  Multiclass Hardware-Friendly Support Vector Machine. International  Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz,  Spain. Dec 2012</tt></p><h2>Download data from source<a name="5"></a></h2><pre>If you are running this script for the first time, make sure that you
execute these functions.</pre><div><ul><li><tt>downloadSensorData</tt> : This function will download the dataset and extract its contents to a folder called: UCI HAR Dataset This folder must be present before you execute <tt>saveSensorDataAsMATFiles</tt></li></ul></div><pre class="codeinput"><span class="keyword">if</span> ~exist(<span class="string">'UCI HAR Dataset'</span>,<span class="string">'file'</span>)
    downloadSensorData;
<span class="keyword">end</span>
</pre><h2>Load data frome individual files and save as MAT file for reuse<a name="7"></a></h2><div><ul><li><tt>saveSensorDataAsMATFiles</tt> : This function will load the data from the individual source files and save the data in a single MAT file for easy accesss</li></ul></div><pre class="codeinput"><span class="keyword">if</span> ~exist(<span class="string">'rawSensorData_train.mat'</span>,<span class="string">'file'</span>) &amp;&amp; ~exist(<span class="string">'rawSensorData_test.mat'</span>,<span class="string">'file'</span>)
    saveSensorDataAsMATFiles;
<span class="keyword">end</span>
</pre><h2>Load Training Data<a name="9"></a></h2><pre class="codeinput">load <span class="string">rawSensorData_train</span>
</pre><h2>Display data summary<a name="10"></a></h2><pre class="codeinput">plotRawSensorData(total_acc_x_train, total_acc_y_train, <span class="keyword">...</span>
    total_acc_z_train,trainActivity,1000)
</pre><img vspace="5" hspace="5" src="Human_Activity_Learning_01.png" alt=""> <h2>Create Table variable<a name="11"></a></h2><pre class="codeinput">rawSensorDataTrain = table(<span class="keyword">...</span>
    total_acc_x_train, total_acc_y_train, total_acc_z_train, <span class="keyword">...</span>
    body_gyro_x_train, body_gyro_y_train, body_gyro_z_train);
</pre><h2>Pre-process Training Data: <b>Feature Extraction</b><a name="12"></a></h2><p>Lets start with a simple preprocessing technique. Since the raw sensor data contain fixed-width sliding windows of 2.56sec (128 readings/window) lets start with a simple average feature for every 128 points</p><pre class="codeinput">humanActivityData = varfun(@Wmean,rawSensorDataTrain);
humanActivityData.activity = trainActivity;
</pre><h2>Train a model and assess its performance using Classification Learner<a name="13"></a></h2><pre class="codeinput">classificationLearner
</pre><h2>Additional Feature Extraction<a name="14"></a></h2><pre class="codeinput">T_mean = varfun(@Wmean, rawSensorDataTrain);
T_stdv = varfun(@Wstd,rawSensorDataTrain);
T_pca  = varfun(@Wpca1,rawSensorDataTrain);

humanActivityData = [T_mean, T_stdv, T_pca];
humanActivityData.activity = trainActivity;
</pre><h2>Use the new features to train a model and assess its performance<a name="15"></a></h2><pre class="codeinput">classificationLearner
</pre><p><img vspace="5" hspace="5" src="classificationLearner.png" alt=""> </p><h2>Load Test Data<a name="17"></a></h2><pre class="codeinput">load <span class="string">rawSensorData_test</span>
</pre><h2>Visualize classifier performance on test data<a name="18"></a></h2><p>Step 1: Create a table</p><pre class="codeinput">rawSensorDataTest = table(<span class="keyword">...</span>
    total_acc_x_test, total_acc_y_test, total_acc_z_test, <span class="keyword">...</span>
    body_gyro_x_test, body_gyro_y_test, body_gyro_z_test);

<span class="comment">% Step 2: Extract features from raw sensor data</span>
T_mean = varfun(@Wmean, rawSensorDataTest);
T_stdv = varfun(@Wstd,rawSensorDataTest);
T_pca  = varfun(@Wpca1,rawSensorDataTest);

humanActivityData = [T_mean, T_stdv, T_pca];
humanActivityData.activity = testActivity;

<span class="comment">% Step 3: Use trained model to predict activity on new sensor data</span>
<span class="comment">% Make sure that you've exported 'trainedClassifier' from</span>
<span class="comment">% ClassificationLearner</span>
plotActivityResults(trainedClassifier,rawSensorDataTest,humanActivityData,0.1)
</pre><p><img vspace="5" hspace="5" src="PredictionResults.png" alt=""> </p><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Human Activity Learning Using Mobile Phone Data
% Human activity sensor data contains observations derived from
% sensor measurements taken from smartphones worn by people while doing
% different activities (walking, lying, sitting etc). The goal of this 
% example is to provide a strategy to build a classifier that can 
% automatically identify the activity type given the sensor measurements. 
%
% Copyright (c) 2015, MathWorks, Inc.

%% Description of the Data
%  The dataset consists of accelerometer and gyroscope data captured at 
% 50Hz. The raw sensor data contain fixed-width sliding windows of 2.56 sec 
% (128 readings/window). The activities performed by the subject include:
% 'Walking', 'ClimbingStairs', 'Sitting', 'Standing',and 'Laying'
%%
% *How to get the data:*
% Execute |downloadSensorData| and follow the instructions to download the
% and extract the data from the source webpage. After the files have been
% extracted run |saveSensorDataAsMATFiles|. This will create two MAT files: 
% |rawSensorData_train|  and |rawSensorData_test| with the raw sensor data
%%
% # *total_acc_(x/y/z)_train :*  Raw accelerometer sensor data
% # *body_gyro_(x/y/z)_train :*  Raw gyroscope sensor data 
% # *trainActivity :*  Training data labels
% # *testActivity  :*  Test data labels

%%
% Reference:
% 
% |Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L.
%  Reyes-Ortiz. Human Activity Recognition on Smartphones using a
%  Multiclass Hardware-Friendly Support Vector Machine. International
%  Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz,
%  Spain. Dec 2012|

%% Download data from source
%  If you are running this script for the first time, make sure that you
%  execute these functions. 
%%
% * |downloadSensorData| : This function will download the dataset and
% extract its contents to a folder called: UCI HAR Dataset
% This folder must be present before you execute |saveSensorDataAsMATFiles|
if ~exist('UCI HAR Dataset','file')
    downloadSensorData;
end

%% Load data frome individual files and save as MAT file for reuse
%%
% * |saveSensorDataAsMATFiles| : This function will load the data from the individual
% source files and save the data in a single MAT file for easy accesss 
if ~exist('rawSensorData_train.mat','file') && ~exist('rawSensorData_test.mat','file')
    saveSensorDataAsMATFiles;
end

%% Load Training Data
load rawSensorData_train

%% Display data summary
plotRawSensorData(total_acc_x_train, total_acc_y_train, ...
    total_acc_z_train,trainActivity,1000)

%% Create Table variable
rawSensorDataTrain = table(...
    total_acc_x_train, total_acc_y_train, total_acc_z_train, ...
    body_gyro_x_train, body_gyro_y_train, body_gyro_z_train);

%% Pre-process Training Data: *Feature Extraction*
% Lets start with a simple preprocessing technique. Since the raw sensor 
% data contain fixed-width sliding windows of 2.56sec (128 readings/window) 
% lets start with a simple average feature for every 128 points

humanActivityData = varfun(@Wmean,rawSensorDataTrain);
humanActivityData.activity = trainActivity;

%% Train a model and assess its performance using Classification Learner
classificationLearner

%% Additional Feature Extraction

T_mean = varfun(@Wmean, rawSensorDataTrain);
T_stdv = varfun(@Wstd,rawSensorDataTrain);
T_pca  = varfun(@Wpca1,rawSensorDataTrain);

humanActivityData = [T_mean, T_stdv, T_pca];
humanActivityData.activity = trainActivity;

%% Use the new features to train a model and assess its performance 
classificationLearner
%%
% 
% <<classificationLearner.png>>
% 

%% Load Test Data
load rawSensorData_test

%% Visualize classifier performance on test data
%
% Step 1: Create a table
rawSensorDataTest = table(...
    total_acc_x_test, total_acc_y_test, total_acc_z_test, ...
    body_gyro_x_test, body_gyro_y_test, body_gyro_z_test);

% Step 2: Extract features from raw sensor data
T_mean = varfun(@Wmean, rawSensorDataTest);
T_stdv = varfun(@Wstd,rawSensorDataTest);
T_pca  = varfun(@Wpca1,rawSensorDataTest);

humanActivityData = [T_mean, T_stdv, T_pca];
humanActivityData.activity = testActivity;

% Step 3: Use trained model to predict activity on new sensor data
% Make sure that you've exported 'trainedClassifier' from
% ClassificationLearner
plotActivityResults(trainedClassifier,rawSensorDataTest,humanActivityData,0.1)

%%
% 
% <<PredictionResults.png>>
% 



##### SOURCE END #####
--></body></html>